{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPU/SKp6yDl7Q4+zmUuD8ir",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prajaktakini/Implement-RNN-From-Scratch/blob/main/From_Scratch_RNN_Encoder_Decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXNVXDABTZSE",
        "outputId": "33dbc1fa-d30d-47ec-f2f2-084755016c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = '/content/drive/My Drive/Projects/Language Models'\n"
      ],
      "metadata": {
        "id": "yxKBp5dbTagr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FLfZF3E_h2o8",
        "outputId": "076afbab-6bdc-4ddb-bd6c-c41143480bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.15.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.15.0) (1.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.15.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==2.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from collections import Counter\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import nltk"
      ],
      "metadata": {
        "id": "FtElQcqKh7Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "\n",
        "  def __init__(self, pad_token='<pad>', unk_token='<unk>', start_token = '<s>', end_token = '</s>'):\n",
        "      self.word2idx = {\n",
        "          pad_token: 0,\n",
        "          unk_token: 1,\n",
        "          start_token: 2,\n",
        "          end_token: 3\n",
        "      }\n",
        "      self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
        "      self.special_tokens = [pad_token, unk_token, start_token, end_token]\n",
        "\n",
        "\n",
        "  def fit(self, sentences: list[str], min_freq:int=1):\n",
        "      # Build vocabulary from list of sentences\n",
        "      word_counts = Counter()\n",
        "\n",
        "      for sentence in sentences:\n",
        "          words = sentence.strip().split()\n",
        "          word_counts.update(words)\n",
        "\n",
        "      for word, count in word_counts.items():\n",
        "          # Only consider the word which has >= min_freq\n",
        "          if count >= min_freq and word not in self.word2idx:\n",
        "              self.word2idx[word] = len(self.word2idx)\n",
        "              self.idx2word[len(self.idx2word)] = word\n",
        "\n",
        "\n",
        "  def encode(self, sentence: str, add_special_tokens: bool = True):\n",
        "      words = sentence.strip().split()\n",
        "      if add_special_tokens:\n",
        "          words = [self.special_tokens[2]] + words + [self.special_tokens[3]]\n",
        "\n",
        "      # Get index of every word in this sentence, if this word does not appear in the vocab dictionary, return self.special_tokens[1] = \"<unk>\"\n",
        "      return [self.word2idx.get(word, self.word2idx[self.special_tokens[1]]) for word in words]\n",
        "\n",
        "\n",
        "  def decode(self, indices: list[int], skip_special_tokens: bool = True):\n",
        "      # Converts sequence of indices to sequence of words\n",
        "\n",
        "      words = [self.idx2word[idx] for idx in indices]\n",
        "      if skip_special_tokens:\n",
        "          words = [word for word in words if word not in self.special_tokens]\n",
        "      return \" \".join(words)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.word2idx)\n"
      ],
      "metadata": {
        "id": "36BxdgYih8Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://huggingface.co/datasets/anujsahani01/English-Marathi\n",
        "class TranslationDataset(Dataset):\n",
        "\n",
        "  def __init__(self, english_setences: list[str], marathi_setences: list[str], en_tokenizer: Tokenizer, mar_tokenizer: Tokenizer):\n",
        "    self.english_sentences = english_setences\n",
        "    self.marathi_sentences = marathi_setences\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.mar_tokenizer = mar_tokenizer\n",
        "\n",
        "    # Pad and mask sequences during dataset preparation\n",
        "    self.padded_data = self._pad_and_mask_sequences()\n",
        "\n",
        "\n",
        "  def _pad_and_mask_sequences(self):\n",
        "    # Pad and mask sequences during dataset preparation\n",
        "    padded_data = []\n",
        "\n",
        "    max_en_length = 105\n",
        "    max_mr_length = 105\n",
        "\n",
        "    for en_sentence, mr_sentence in zip(self.english_sentences, self.marathi_sentences):\n",
        "      en_encoded = self.en_tokenizer.encode(en_sentence)\n",
        "      mr_encoded = self.mar_tokenizer.encode(mr_sentence)\n",
        "\n",
        "      # pad sequences\n",
        "      en_padded = en_encoded + [self.en_tokenizer.word2idx['<pad>']] * (max_en_length - len(en_encoded))\n",
        "      mr_padded = mr_encoded + [self.mar_tokenizer.word2idx['<pad>']] * (max_mr_length - len(mr_encoded))\n",
        "\n",
        "      # create attention masks\n",
        "      en_mask = [1] * len(en_encoded) + [0] * (max_en_length - len(en_encoded))\n",
        "      mr_mask = [1] * len(mr_encoded) + [0] * (max_mr_length - len(mr_encoded))\n",
        "\n",
        "      padded_data.append({\n",
        "          \"en_text\": en_sentence,\n",
        "          \"mr_text\": mr_sentence,\n",
        "          \"en_input_ids\": en_padded,\n",
        "          \"mr_input_ids\": mr_padded,\n",
        "          \"en_attention_mask\": en_mask,\n",
        "          \"mr_attention_mask\": mr_mask,\n",
        "      })\n",
        "\n",
        "    return padded_data\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.english_sentences)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.padded_data[index]\n"
      ],
      "metadata": {
        "id": "ourq4D-ViH8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Helper:\n",
        "\n",
        "  def collate_batch(batch, device):\n",
        "    \"Collate batch of examples with padding\"\n",
        "\n",
        "    # convert lists to tensors\n",
        "    en_input_ids = torch.tensor([item['en_input_ids'] for item in batch], dtype=torch.long).to(device)\n",
        "    mr_input_ids = torch.tensor([item['mr_input_ids'] for item in batch], dtype=torch.long).to(device)\n",
        "    en_attention_mask = torch.tensor([item['en_attention_mask'] for item in batch], dtype=torch.bool).to(device)\n",
        "    mr_attention_mask = torch.tensor([item['mr_attention_mask'] for item in batch], dtype=torch.bool).to(device)\n",
        "\n",
        "    return {\n",
        "        \"en_input_ids\": en_input_ids,\n",
        "        \"mr_input_ids\": mr_input_ids,\n",
        "        \"en_attention_mask\": en_attention_mask,\n",
        "        \"mr_attention_mask\": mr_attention_mask,\n",
        "        \"en_text\": [item['en_text'] for item in batch],\n",
        "        \"mr_text\": [item['mr_text'] for item in batch]\n",
        "    }"
      ],
      "metadata": {
        "id": "wPurEO3fjeUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # For numerical stability\n",
        "    return exp_x / np.sum(exp_x, axis=0)"
      ],
      "metadata": {
        "id": "DygCi5XVjeSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN:\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, device):\n",
        "      self.vocab_size = vocab_size # Size of the vocabulary\n",
        "      self.embedding_dim = embedding_dim # Size of the embedding vectors\n",
        "      self.hidden_size = hidden_size\n",
        "      self.device = device\n",
        "\n",
        "      # Embedding layer: maps token indices to dense vectors\n",
        "      self.embedding = torch.nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "\n",
        "      # Encoder parameters\n",
        "      self.W_ih = torch.randn(hidden_size, embedding_dim, device=device) * (2.0 / embedding_dim) ** 0.5 # Input to hidden\n",
        "      self.W_hh = torch.randn(hidden_size, hidden_size, device=device) * (2.0 / hidden_size) ** 0.5 # Hidden to Hidden\n",
        "      self.b_h = torch.zeros(hidden_size, 1, device=device) # Hidden bias\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "      batch_size, seq_len = input_seq.shape # Input shape: (batch_size, seq_length)\n",
        "\n",
        "      # Convert token indices to dense vectors\n",
        "      inputs_embedded = self.embedding(input_seq.to(self.device)) # Shape: (batch_size, seq_length, embedding_dim)\n",
        "\n",
        "      hidden_state = torch.zeros(batch_size, self.hidden_size, 1, device=self.device) # (batch, hidden, 1) # Move hidden state to GPU\n",
        "      hidden_states = [] # This will store tensors, so ensure they are on the GPU\n",
        "\n",
        "      # Process each time step\n",
        "      for t in range(seq_len):\n",
        "          hidden_state = torch.tanh(\n",
        "                torch.einsum('ij,bj->bi', self.W_ih, inputs_embedded[:, t, :])[:, :, None] +\n",
        "                torch.einsum('ij,bj->bi', self.W_hh, hidden_state[:, :, 0])[:, :, None] +\n",
        "                self.b_h\n",
        "            )\n",
        "          # H * embedding dim batch size * embedding dim -> batch size * hidden size * 1\n",
        "          # H * H, Batch * Hidden -> Batch * Hidden * 1\n",
        "          # +\n",
        "          # print(\"hidden state \")\n",
        "          # print(hidden_state.shape)\n",
        "          # print(hidden_state)\n",
        "          hidden_states.append(hidden_state) # Each hidden_state is already on the GPU\n",
        "\n",
        "\n",
        "      return hidden_states[-1], hidden_states\n",
        "\n",
        "\n",
        "    def backward(self, d_hidden, inputs, enc_hidden_states, learning_rate=1e-3):\n",
        "      batch_size, seq_len = inputs.shape\n",
        "      dW_ih, dW_hh = torch.zeros_like(self.W_ih), torch.zeros_like(self.W_hh)\n",
        "      db_h = torch.zeros_like(self.b_h)\n",
        "\n",
        "      # Convert token indices to dense vectors\n",
        "      inputs_embedded = self.embedding(inputs.to(self.device)) # Shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "      for t in reversed(range(seq_len)):\n",
        "          # Derivative of tanh\n",
        "          d_hidden = d_hidden * (1 - enc_hidden_states[t] ** 2) # Shape: (batch_size, hidden_size, 1)\n",
        "\n",
        "\n",
        "          # Gradients for input-to-hidden and hidden-to-hidden weights\n",
        "          dW_ih += torch.einsum('bi,bj->ij', d_hidden[:, :, 0], inputs_embedded[:, t, :]) # batch * hidden * (batch, embedding) -> hidden * embedding\n",
        "          dW_hh += torch.einsum('bi,bj->ij', d_hidden[:, :, 0], (enc_hidden_states[t - 1][:, :, 0] if t > 0 else torch.zeros_like(enc_hidden_states[0][:, :, 0])))\n",
        "          # enc_hidden_state[t - 1] = shape(batch, hidden, 1)\n",
        "          # (batch * hidden) * (batch * hidden) -> (hidden * hidden)\n",
        "          db_h += torch.sum(d_hidden, dim=0) # Shape: (hidden, 1)\n",
        "\n",
        "          # Propagate gradients to previous time step\n",
        "          d_hidden = torch.einsum('ij,bj->bi', self.W_hh.T, d_hidden[:, :, 0])[:, :, None] # (hidden * hidden) * (batch * hidden) -> (batcj * hidden, 1)\n",
        "\n",
        "\n",
        "\n",
        "      # Update parameters using gradient descent\n",
        "      self.W_ih -= learning_rate * dW_ih / batch_size\n",
        "      self.W_hh -= learning_rate * dW_hh / batch_size\n",
        "      self.b_h -= learning_rate * db_h / batch_size\n"
      ],
      "metadata": {
        "id": "NH69Z0C5jeRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DecoderRNN:\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, device):\n",
        "      self.vocab_size = vocab_size # Size of the vocabulary\n",
        "      self.embedding_dim_enc = embedding_dim # Size of the embedding vectors\n",
        "      self.hidden_size = hidden_size\n",
        "      self.device = device\n",
        "\n",
        "      # Embedding Layer: Maps token indices to dense vectors\n",
        "      self.embedding = torch.nn.Embedding(vocab_size, embedding_dim).to(device) # we are doing neural machine translation so languages are not shared between Encoder and Decoder hence define another embedding layer\n",
        "\n",
        "      # Decoder parameters\n",
        "      self.W_ih = torch.randn(hidden_size, embedding_dim, device=device) * (2.0 / embedding_dim) ** 0.5 # Input to hidden\n",
        "      self.W_hh = torch.randn(hidden_size, hidden_size, device=device) * (2.0 / hidden_size) ** 0.5 # Hidden to Hidden\n",
        "      self.W_ho = torch.randn(vocab_size, hidden_size, device=device) * (2.0 / hidden_size) ** 0.5 # Hidden to Output\n",
        "\n",
        "      self.b_h = torch.zeros(hidden_size, 1, device=device) # Hidden bias\n",
        "      self.b_o = torch.zeros(vocab_size, 1, device=device) # Output bias\n",
        "\n",
        "\n",
        "    def forward(self, target_seq, hidden_state):\n",
        "      batch_size, seq_len = target_seq.shape\n",
        "      target_embedded = self.embedding(target_seq.to(self.device)) # Use decoder embedding # Shape: (batch_size, seq_length, embedding_dim)\n",
        "\n",
        "      outputs, predictions = [], []\n",
        "      loss = 0\n",
        "      hidden_states = []  # Store hidden states\n",
        "\n",
        "      for t in range(seq_len):\n",
        "          # Update hidden state\n",
        "          hidden_state = torch.tanh(\n",
        "                torch.einsum('ij,bj->bi', self.W_ih, target_embedded[:, t, :])[:, :, None] +\n",
        "                torch.einsum('ij,bj->bi', self.W_hh, hidden_state[:, :, 0])[:, :, None] +\n",
        "                self.b_h\n",
        "            )\n",
        "          hidden_states.append(hidden_state)\n",
        "\n",
        "#h * e * b * e -> b * h\n",
        "\n",
        "          #output = torch.einsum('ij,bj->bi', self.W_ho, hidden_state[:, :, 0]) + self.b_o\n",
        "          output = torch.einsum('ij,bj->bi', self.W_ho, hidden_state.squeeze(-1)) + self.b_o.squeeze(-1)\n",
        "\n",
        "          # Calculate Probabilities with Numerical Stability\n",
        "          output_exp = torch.exp(output - torch.max(output, dim=1, keepdim=True).values)\n",
        "          probs = output_exp / torch.sum(output_exp, dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "          # Calculate Loss with Epsilon\n",
        "          epsilon = 1e-8  # Small positive value\n",
        "          loss -= torch.sum(torch.log(probs + epsilon)[torch.arange(batch_size), torch.argmax(target_embedded[:, t, :], dim=1)])\n",
        "\n",
        "          outputs.append(probs)\n",
        "          predictions.append(torch.argmax(probs, dim=1))\n",
        "\n",
        "      return torch.stack(outputs), loss / (batch_size * seq_len), hidden_states\n",
        "\n",
        "\n",
        "    def backward(self, outputs, target_seq, dec_hidden_states, learning_rate=1e-3):\n",
        "        batch_size, seq_len = target_seq.shape\n",
        "        target_embedded = self.embedding(target_seq.to(self.device)) # Use decoder embedding # Shape: (batch_size, seq_length, embedding_dim)\n",
        "\n",
        "\n",
        "        dW_ih, dW_hh, dW_ho = torch.zeros_like(self.W_ih), torch.zeros_like(self.W_hh), torch.zeros_like(self.W_ho)\n",
        "        db_h, db_o = torch.zeros_like(self.b_h), torch.zeros_like(self.b_o)\n",
        "        d_hidden = torch.zeros(batch_size, self.hidden_size, 1, device=self.device)\n",
        "\n",
        "        # Convert target tokens to one-hot vectors\n",
        "        target_one_hot = torch.zeros(batch_size, seq_len, self.vocab_size, device=self.device)\n",
        "        target_one_hot.scatter_(dim=2, index=target_seq.unsqueeze(-1), value=1)  # Shape: (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        # Convert token indices to dense vectors\n",
        "        #target_embedded = self.embedding(target_seq) # Shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        for t in reversed(range(seq_len)):\n",
        "\n",
        "\n",
        "            # Output error (Gradient of Softmax)\n",
        "            output_error = (outputs[t] - target_one_hot[:, t, :])[:, :, None] # Shape: (batch_size, vocab_size, 1)\n",
        "\n",
        "\n",
        "            # dec_hidden_states = # (batch, hidden, 1)\n",
        "            # Gradients for output layer\n",
        "            dW_ho += torch.einsum('bi,bj->ij', output_error[:, :, 0], dec_hidden_states[t][:, :, 0])  # batch * vocab * (batch * hidden) -> vocab * hidden\n",
        "            db_o += torch.sum(output_error, dim=0) # (vocab, 1)\n",
        "\n",
        "            # Gradients for hidden state\n",
        "            d_hidden = torch.einsum('ji,bj->bi', self.W_ho, output_error[:, :, 0])[:, :, None] + d_hidden # vocab * hidden * (batch * vocab) -> batch * hidden * 1\n",
        "            d_hidden *= (1 - dec_hidden_states[t] ** 2) # Derivative of tanh\n",
        "\n",
        "            # Gradients for input-to-hidden and hidden-to-hidden weights\n",
        "            dW_ih += torch.einsum('bi,bj->ij', d_hidden[:, :, 0], target_embedded[:, t, :]) # batch * hidden * (batch, embedding) -> (hidden * embedding)\n",
        "            dW_hh += torch.einsum('bi,bj->ij', d_hidden[:, :, 0], (dec_hidden_states[t - 1][:, :, 0] if t > 0 else torch.zeros_like(dec_hidden_states[0][:, :, 0])))\n",
        "            # dec_hidden_state = batch * hidden so batch * hidden * (batch * hidden) -> hidden * hidden\n",
        "            db_h += torch.sum(d_hidden, dim=0) # (hidden , 1)\n",
        "\n",
        "            # Propagate gradients to previous time step\n",
        "            if t > 0:  # Only propagate if we're not at the first timestep\n",
        "                d_hidden = torch.einsum('ij,bj->bi', self.W_hh.T, d_hidden[:, :, 0])[:, :, None] # (hidden * hidden) * (batch * hidden) -> (batch * hidden * 1)\n",
        "\n",
        "\n",
        "        # Update parameters using gradient descent\n",
        "        self.W_ih -= learning_rate * dW_ih / batch_size\n",
        "        self.W_hh -= learning_rate * dW_hh / batch_size\n",
        "        self.W_ho -= learning_rate * dW_ho / batch_size\n",
        "        self.b_h -= learning_rate * db_h / batch_size\n",
        "        self.b_o -= learning_rate * db_o / batch_size\n",
        "\n",
        "        return d_hidden"
      ],
      "metadata": {
        "id": "p9jCRNi8jxG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoderRNN:\n",
        "\n",
        "    def __init__(self, en_tokenizer, mr_tokenizer, device):\n",
        "        self.en_tokenizer = en_tokenizer\n",
        "        self.mr_tokenizer = mr_tokenizer\n",
        "        self.vocab_size_en = len(en_tokenizer)\n",
        "        self.vocab_size_mr = len(mr_tokenizer)\n",
        "        self.embedding_dim = 300\n",
        "        self.hidden_size = 512\n",
        "        self.device = device\n",
        "\n",
        "        self.encoder = EncoderRNN(self.vocab_size_en, self.embedding_dim, self.hidden_size, device)\n",
        "        self.decoder = DecoderRNN(self.vocab_size_mr, self.embedding_dim, self.hidden_size, device)\n",
        "\n",
        "    def train(self, train_loader, num_epochs=10):\n",
        "\n",
        "            encoder = self.encoder\n",
        "            decoder = self.decoder\n",
        "\n",
        "            for epoch in range(num_epochs):\n",
        "                total_loss = 0\n",
        "                for batch in train_loader:\n",
        "                    en_input_ids = batch[\"en_input_ids\"].to(self.device)\n",
        "                    mr_input_ids = batch[\"mr_input_ids\"].to(self.device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    # print(\"en_input_ids_shape\")\n",
        "                    # print(en_input_ids.shape)\n",
        "                    hidden_state, enc_hidden_states = encoder.forward(en_input_ids)\n",
        "\n",
        "                    # print(\"hidden state shape train\")\n",
        "                    # print(hidden_state.shape)\n",
        "\n",
        "                    # print(\"train decoder input shape\")\n",
        "                    # print(mr_input_ids.shape)\n",
        "                    outputs, loss, dec_hidden_states = decoder.forward(mr_input_ids, hidden_state)\n",
        "\n",
        "\n",
        "\n",
        "                    # Backward pass and optimization\n",
        "                    decoder_grad = decoder.backward(outputs, mr_input_ids, dec_hidden_states)\n",
        "                    encoder.backward(decoder_grad, en_input_ids, enc_hidden_states)\n",
        "\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "            print(f\"Epoch {epoch + 1} / {num_epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    def predict(self, sentence, en_tokenizer, mr_tokenizer, max_length=50):\n",
        "        # Tokenize the input sentence\n",
        "\n",
        "        input_seq = torch.tensor(en_tokenizer.encode(sentence), dtype=torch.long).unsqueeze(0).to(self.device)\n",
        "\n",
        "        print(\"input_seq_shape\")\n",
        "        print(input_seq.shape)\n",
        "        print(input_seq)\n",
        "\n",
        "        # Pass through the encoder\n",
        "        hidden_state, _ = self.encoder.forward(input_seq)\n",
        "\n",
        "        print(\"hidden state shape predict\")\n",
        "        print(hidden_state.shape)\n",
        "\n",
        "\n",
        "        # Initialize the decoder input with the start token\n",
        "        start_token = mr_tokenizer.word2idx['<s>']\n",
        "        decoder_input = torch.tensor([[start_token]], dtype=torch.long).to(self.device)\n",
        "\n",
        "        print(\"predict decoder_input shape\")\n",
        "        print(decoder_input.shape)\n",
        "\n",
        "        # Initialize the output sequence\n",
        "        output_seq = []\n",
        "\n",
        "        # Generate the output sequence\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through the decoder\n",
        "            outputs, _, dec_hidden_states = self.decoder.forward(decoder_input, hidden_state) # (batch size, seq_len, vocab) i.e. (1, 1, 689)\n",
        "            hidden_state = dec_hidden_states[-1] # Get the last hidden state for the next time step\n",
        "\n",
        "            print(\"outputs shape\")\n",
        "            print(outputs.shape)\n",
        "            #print(outputs)\n",
        "\n",
        "            # Get the predicted token (greedy decoding)\n",
        "            probs = outputs[:, -1, :]  # Get probabilities for the last token in the sequence (1, 689)\n",
        "\n",
        "            # Get the predicted token (greedy decoding)\n",
        "            predicted_token = torch.argmax(probs, dim=-1)\n",
        "            predicted_token = predicted_token.item() if predicted_token.numel() == 1 else predicted_token\n",
        "            print(\"predicted token \")\n",
        "            #print(predicted_token.shape)\n",
        "            print(predicted_token)\n",
        "\n",
        "            #predicted_token =  torch.argmax(probs, dim=-1).item() if probs.dim() == 1 else torch.argmax(probs, dim=-1) # This is where the problem is most likely.\n",
        "\n",
        "\n",
        "            # Append the predicted token to the output sequence\n",
        "            output_seq.append(predicted_token)\n",
        "\n",
        "            # Break if the end token is generated\n",
        "            if predicted_token == mr_tokenizer.word2idx['</s>']:\n",
        "                break\n",
        "\n",
        "            # Update the decoder input for the next time step\n",
        "            decoder_input = torch.tensor([[predicted_token]], dtype=torch.long).to(self.device)\n",
        "\n",
        "        # Convert the output sequence to a sentence\n",
        "        predicted_sentence = mr_tokenizer.decode(output_seq, skip_special_tokens=True)\n",
        "\n",
        "        return predicted_sentence\n"
      ],
      "metadata": {
        "id": "BJutgR2ajeOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9z4EwtejeMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Below code cells can be ignored if you load data from Excel file"
      ],
      "metadata": {
        "id": "yGPXxRWmS4Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "dataset = load_dataset(\"anujsahani01/English-Marathi\")\n",
        "\n",
        "train_data = dataset[\"train\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "english_sentences = [item[\"english\"] for item in train_data]\n",
        "marathi_sentences = [item[\"marathi\"] for item in train_data]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OdWOhTM3jeJv",
        "outputId": "315687b1-8b99-4f1b-b0d6-d323e2b636d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5ee542c1e82f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anujsahani01/English-Marathi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize sentences\n",
        "english_tokenized = [sentence.split() for sentence in english_sentences]\n",
        "marathi_tokenized = [sentence.split() for sentence in marathi_sentences]\n",
        "\n",
        "# Calculate lengths\n",
        "english_lengths = [len(tokens) for tokens in english_tokenized]\n",
        "marathi_lengths = [len(tokens) for tokens in marathi_tokenized]\n",
        "\n",
        "\n",
        "filtered_english_sentences = []\n",
        "filtered_marathi_sentences = []\n",
        "max_token_len = 95\n",
        "# Filter English and Marathi sentences\n",
        "for i in range(len(english_sentences)):\n",
        "    if len(english_tokenized[i]) <= max_token_len and len(marathi_tokenized[i]) <= max_token_len:\n",
        "        filtered_english_sentences.append(english_sentences[i])\n",
        "        filtered_marathi_sentences.append(marathi_sentences[i])"
      ],
      "metadata": {
        "id": "d9U6yk11jz4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample 10,000 sentences\n",
        "random.seed(42)  # For reproducibility\n",
        "sampled_indices = random.sample(range(len(filtered_english_sentences)), 10000)\n",
        "sampled_english = [filtered_english_sentences[i] for i in sampled_indices]\n",
        "sampled_marathi = [filtered_marathi_sentences[i] for i in sampled_indices]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "RV9hzCaMVFIn",
        "outputId": "6d630a20-8729-4fff-d963-c55abed97d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'filtered_english_sentences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e19249fb9ff6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Randomly sample 10,000 sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# For reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msampled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_english_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msampled_english\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfiltered_english_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msampled_marathi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfiltered_marathi_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filtered_english_sentences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'English': sampled_english, 'Marathi': sampled_marathi})\n",
        "\n",
        "file_path = drive_path + '/filtered_sentences.xlsx'\n",
        "df.to_excel(file_path, index=False)\n"
      ],
      "metadata": {
        "id": "ZFbFq-s2TQRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data from Excel file"
      ],
      "metadata": {
        "id": "PAc1KeiES5-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = drive_path + '/filtered_sentences.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "sampled_english = df['English'].tolist()\n",
        "sampled_marathi = df['Marathi'].tolist()"
      ],
      "metadata": {
        "id": "wSQlZn3VTizj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split into train (8,000) and test (2,000)\n",
        "train_english = sampled_english[:800]\n",
        "train_marathi = sampled_marathi[:800]\n",
        "test_english = sampled_english[800:1000]\n",
        "test_marathi = sampled_marathi[800:1000]\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Total sampled sentences: {len(sampled_english)}\")\n",
        "print(f\"Train sentences: {len(train_english)}\")\n",
        "print(f\"Test sentences: {len(test_english)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2W2Cw1VkiVB",
        "outputId": "33a52a69-5878-4b90-92be-f7a2757de46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sampled sentences: 10000\n",
            "Train sentences: 800\n",
            "Test sentences: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_english[0:10])\n",
        "print(train_marathi[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VU5-6Jf1mLrK",
        "outputId": "adf15e45-6cda-47fa-9e70-d848b9174421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"BJP's Amrish Patel wins from Dhule-Nandurbar\", 'im not a small dude.', 'Causes for depression', '\"The servant answered Saul again, and said, \"\"Behold, I have in my hand the fourth part of a shekel of silver. I will give that to the man of God, to tell us our way.\"\"\"', 'In addition, antiviral drug 3D printed mask, nanofiber coated N-95 mask, Povidone Iodine thin-film coated mask is being proposed for mass consumption.', '\"\"\"Our opponents are conspiring against us by trying to lay a foundation for caste and communal riots through international funding.\"', 'Today I am the most happy guy in the world.', \"The movie is directed by Farhan Akhtar's sister Zoya Akhtar.\", 'People whose yearly income is less than Rs 8 lakh can avail of this reservation.', 'Healthy wholesome breakfast: It is very important to have a nutritious breakfast to kick-start a hiking trip as it will keep you going.']\n",
            "['विधान परिषदेच्या धुळे-नंदुरबार पोटनिवडणुकीत भाजपाचे अमरिश पटेल यांचा विजय झाला.', 'मी मामूली मुलगी नाही.', 'डिप्रेशनमध्ये जाण्यायामागची कारणं', 'तेव्हा पुन्हा नोकाराने सांगितले, “माझ्याकडे थोडे पैसे आहेत तेच आपण त्या परमेश्वराच्या माणसाला देऊ. मग तो आपल्याला पुढची वाट दाखवेल.”', 'फेस मास्क आणि नेहमीचे मास्क यावर प्रामुख्याने बरेचसे प्रस्ताव होते.याशिवाय एन्टीव्हायरल ड्रग 3 डी प्रिंटेड मास्क, नॅनोफायबर कोटेड एन-95 मास्क साठीही प्रस्ताव आले.', \"'आमचे विरोधक आंतरराष्\\u200dट्रीय फंडिंगच्या माध्यमाने जात आणि संप्रदायावर आधारीत दंगलींचा पाया घालून आमच्या विरोधात कट-कारस्थान आखत आहेत.\", 'या क्षणाला मी या जगातला सर्वात आनंदी माणूस आहे.', '‘गली ब्वॉय’ या सिनेमाचं दिग्दर्शन फरहान अख्तर याची बहिणी झोया अख्तर ही करणार आहे.', 'ज्यांचं उत्पन्न 8 लाख रुपयांपेक्षा कमी आहे, त्यांना हे आरक्षण मिळेल.', '>> आरोग्यदायी पौष्टिक ब्रेकफाटसह दिवसाची सुरुवात करा: तुमच्या हायकिंग ट्रिपची सुरुवात करण्यासाठी पौष्टिक ब्रेकफास्ट सेवन करणे अत्यंत महत्त्वाचे आहे.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Tokenization\n",
        "en_tokenizer = Tokenizer()\n",
        "mr_tokenizer = Tokenizer()\n",
        "\n",
        "# Fit data\n",
        "en_tokenizer.fit(train_english)\n",
        "mr_tokenizer.fit(train_marathi)"
      ],
      "metadata": {
        "id": "3thnnmwFkwlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mr_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VAq01cgmpQX",
        "outputId": "d8f14830-9323-45b8-e466-52c3084b1657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22747"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create dataset\n",
        "dataset = TranslationDataset(train_english, train_marathi, en_tokenizer, mr_tokenizer)\n",
        "\n",
        "batch_size = 32\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=lambda batch: Helper.collate_batch(batch, device), shuffle=True)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "\n",
        "# Create an instance of EncoderDecoderRNN\n",
        "encoder_decoder = EncoderDecoderRNN(en_tokenizer, mr_tokenizer, device)\n",
        "\n",
        "# Call the train method on the instance\n",
        "encoder_decoder.train(dataloader, num_epochs)\n",
        "\n"
      ],
      "metadata": {
        "id": "PcF5eiw81oHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b7341934-7fc3-43f8-ebb1-11a000127ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 17456 has 14.74 GiB memory in use. Of the allocated memory 14.40 GiB is allocated by PyTorch, and 217.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-691df524eea3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Call the train method on the instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c996ffb9c83b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;31m# print(\"train decoder input shape\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;31m# print(mr_input_ids.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmr_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-918bb7d8690d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, target_seq, hidden_state)\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0;31m# Calculate Loss with Epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m           \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m  \u001b[0;31m# Small positive value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_embedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 17456 has 14.74 GiB memory in use. Of the allocated memory 14.40 GiB is allocated by PyTorch, and 217.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"Causes for depression\"\n",
        "\n",
        "translated_sentence = encoder_decoder.predict(test_sentence, en_tokenizer, mr_tokenizer)\n",
        "print(f\"Translated sentence: {translated_sentence}\")\n",
        "print(len(translated_sentence))"
      ],
      "metadata": {
        "id": "UtHir7bMZPsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mr_tokenizer.idx2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecXREodJ-aKD",
        "outputId": "57561c2f-d287-4234-c8b7-745941c675cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '<pad>', 1: '<unk>', 2: '<s>', 3: '</s>', 4: 'विधान', 5: 'परिषदेच्या', 6: 'धुळे-नंदुरबार', 7: 'पोटनिवडणुकीत', 8: 'भाजपाचे', 9: 'अमरिश', 10: 'पटेल', 11: 'यांचा', 12: 'विजय', 13: 'झाला.', 14: 'मी', 15: 'मामूली', 16: 'मुलगी', 17: 'नाही.', 18: 'डिप्रेशनमध्ये', 19: 'जाण्यायामागची', 20: 'कारणं', 21: 'तेव्हा', 22: 'पुन्हा', 23: 'नोकाराने', 24: 'सांगितले,', 25: '“माझ्याकडे', 26: 'थोडे', 27: 'पैसे', 28: 'आहेत', 29: 'तेच', 30: 'आपण', 31: 'त्या', 32: 'परमेश्वराच्या', 33: 'माणसाला', 34: 'देऊ.', 35: 'मग', 36: 'तो', 37: 'आपल्याला', 38: 'पुढची', 39: 'वाट', 40: 'दाखवेल.”', 41: 'फेस', 42: 'मास्क', 43: 'आणि', 44: 'नेहमीचे', 45: 'यावर', 46: 'प्रामुख्याने', 47: 'बरेचसे', 48: 'प्रस्ताव', 49: 'होते.याशिवाय', 50: 'एन्टीव्हायरल', 51: 'ड्रग', 52: '3', 53: 'डी', 54: 'प्रिंटेड', 55: 'मास्क,', 56: 'नॅनोफायबर', 57: 'कोटेड', 58: 'एन-95', 59: 'साठीही', 60: 'आले.', 61: \"'आमचे\", 62: 'विरोधक', 63: 'आंतरराष्\\u200dट्रीय', 64: 'फंडिंगच्या', 65: 'माध्यमाने', 66: 'जात', 67: 'संप्रदायावर', 68: 'आधारीत', 69: 'दंगलींचा', 70: 'पाया', 71: 'घालून', 72: 'आमच्या', 73: 'विरोधात', 74: 'कट-कारस्थान', 75: 'आखत', 76: 'आहेत.', 77: 'या', 78: 'क्षणाला', 79: 'जगातला', 80: 'सर्वात', 81: 'आनंदी', 82: 'माणूस', 83: 'आहे.', 84: '‘गली', 85: 'ब्वॉय’', 86: 'सिनेमाचं', 87: 'दिग्दर्शन', 88: 'फरहान', 89: 'अख्तर', 90: 'याची', 91: 'बहिणी', 92: 'झोया', 93: 'ही', 94: 'करणार', 95: 'ज्यांचं', 96: 'उत्पन्न', 97: '8', 98: 'लाख', 99: 'रुपयांपेक्षा', 100: 'कमी', 101: 'आहे,', 102: 'त्यांना', 103: 'हे', 104: 'आरक्षण', 105: 'मिळेल.', 106: '>>', 107: 'आरोग्यदायी', 108: 'पौष्टिक', 109: 'ब्रेकफाटसह', 110: 'दिवसाची', 111: 'सुरुवात', 112: 'करा:', 113: 'तुमच्या', 114: 'हायकिंग', 115: 'ट्रिपची', 116: 'करण्यासाठी', 117: 'ब्रेकफास्ट', 118: 'सेवन', 119: 'करणे', 120: 'अत्यंत', 121: 'महत्त्वाचे', 122: 'तुम्हीही', 123: 'व्हिडिओची', 124: 'मजा', 125: 'घेऊ', 126: 'शकता.', 127: 'जे', 128: 'भूतकाळात', 129: 'घडले', 130: 'त्याबाबत', 131: 'अधिक', 132: 'विचार', 133: 'न', 134: 'करता.', 135: 'अथणीमध्ये', 136: 'आठ', 137: 'जण', 138: 'निवडणूक', 139: 'रिंगणात', 140: 'असले', 141: 'तरी', 142: 'मुख्य', 143: 'लढत', 144: 'महेश', 145: 'कुमठळ्ी', 146: 'काँग्रेसचे', 147: 'गजानन', 148: 'मंगसुळी', 149: 'यांच्यात', 150: 'होत', 151: 'संचालनालय', 152: 'पंचायत', 153: 'विभाग', 154: 'त्यामुळे,', 155: 'आपला', 156: 'डेटा', 157: 'चांगले', 158: 'संरक्षित', 159: 'केली', 160: 'जाईल.', 161: 'प्रकाशनाच्या', 162: 'निमित्ताने', 163: 'साहित्य', 164: 'कुणासाठी?', 165: 'तथापि,', 166: 'पाकिस्तान', 167: 'अद्यापही', 168: 'गोष्टीला', 169: 'नकार', 170: 'देत', 171: 'कर्ज', 172: 'घ्यायचे', 173: 'मात्र,', 174: 'अपघातात', 175: 'दोघांचाही', 176: 'जागीच', 177: 'मृत्यू', 178: 'मात्र', 179: 'उपचारादरम्यान', 180: 'त्यांचाही', 181: 'अनाथालय,', 182: 'पादचारी', 183: 'मार्ग,', 184: 'रस्ते,', 185: 'धार्मिक', 186: 'स्थळे', 187: 'अशा', 188: 'ठिकाणी', 189: 'राहणार्\\u200dया', 190: 'मुलांची', 191: 'चौकशी', 192: 'करण्यात', 193: 'आली.', 194: 'अन्न', 195: 'विषबाधा', 196: 'उपचार', 197: 'त्याच्या', 198: 'रूपाने', 199: 'स्वत:च', 200: 'जगत', 201: 'असतो.', 202: 'कर्णधार-', 203: 'रोहित', 204: 'राजपाल,', 205: 'प्रशिक्षक-झिशान', 206: 'अली,', 207: 'संघ', 208: 'व्यवस्थापक-', 209: 'सुंदर', 210: 'अय्यर.', 211: 'राजकीय,', 212: 'सामाजिक', 213: 'कार्यात', 214: 'नेटाने', 215: 'प्रगती', 216: 'करता', 217: 'येईल.', 218: 'धरणे,', 219: 'शाळा', 220: 'कामांचा', 221: 'सपाटा', 222: 'त्यांनी', 223: 'लावला.', 224: 'खूप', 225: 'हा', 226: 'पॅलेस', 227: '२६', 228: 'एकर', 229: 'जमिनीवर', 230: '\"\"\"काय', 231: 'माहीत', 232: 'नाही.\"', 233: 'ते', 234: 'युनायटेड', 235: 'स्टेट्सपासून', 236: 'काही', 237: 'भाजीपाल्याची', 238: 'लागवड', 239: 'सुरू', 240: 'झाली', 241: 'एका', 242: 'उदाहरणावरून', 243: 'समजून', 244: 'या…', 245: '”', 246: 'काय', 247: 'बोलावे?', 248: 'तेही', 249: 'अतिशय', 250: 'गरीब', 251: 'कुटुंबातीलच', 252: 'होते.', 253: 'अग्निशमन', 254: 'दलाचे', 255: 'पथक', 256: 'आगीचे', 257: 'वृत्त', 258: 'समजताच', 259: 'घटनास्थळी', 260: 'पोहोचले', 261: 'कॅशबॅक', 262: 'ग्राहकांना', 263: 'अॅमेझॉन', 264: 'पे', 265: 'वरुन', 266: 'पेमेंट', 267: 'केल्यास', 268: 'बॅलेंसच्या', 269: 'स्वरुपात', 270: 'मिळणार', 271: 'मंगळूर', 272: 'मुंबईदरम्यान', 273: 'गाडी', 274: 'कोकण', 275: 'रेल्वेमार्गावरून', 276: 'धावते.', 277: 'दहशतवादाच्या', 278: 'आरोपावरून', 279: 'जाधव', 280: 'यांना', 281: 'पाकच्या', 282: 'लष्करी', 283: 'न्यायालयाने', 284: 'देहदंडाची', 285: 'शिक्षा', 286: 'सुनावली', 287: 'असं', 288: 'असलं', 289: 'एकदा', 290: 'अवश्य', 291: 'पाहण्यासारखा', 292: 'चित्रपट', 293: 'किमान', 294: 'साडेतीन', 295: 'कॅरेटचा', 296: 'पुष्कराज', 297: 'घातला', 298: 'तर', 299: 'परिणाम', 300: 'जाणवतात.', 301: 'परंतु', 302: 'त्यांच्यापर्यंत', 303: 'पोहोचतच', 304: 'नाहीत.', 305: 'याउलट,', 306: 'लक्षात', 307: 'ठेवले', 308: 'पाहिजे', 309: 'की', 310: 'सर्व', 311: 'प्रकारचे', 312: 'लोक', 313: 'सुवार्तेला', 314: 'योग्य', 315: 'प्रतिसाद', 316: 'देऊ', 317: 'शकतात.', 318: '—', 319: '१', 320: 'करिंथ.', 321: 'हवाई', 322: 'वाहतूक', 323: 'क्षेत्रात', 324: 'आयटी', 325: 'कम्युनिकेशन', 326: 'सेवा', 327: 'पुरवणारी', 328: 'सीटा', 329: 'कंपनी', 330: 'इतके', 331: 'त्रासून', 332: 'जातात.', 333: 'तहसील', 334: 'क्षेत्रातला', 335: 'नेता', 336: 'असो,', 337: 'जिल्हा', 338: 'स्तरावरचा', 339: 'असो', 340: ',', 341: 'राज्यपातळीवरचा', 342: 'नेतो', 343: 'राष्ट्रीय', 344: 'असो.', 345: 'धनतेरसच्या', 346: 'शुभ', 347: 'प्रसंगी', 348: 'सर्वांना', 349: 'शुभेच्छा!', 350: 'त्याच्याकडे', 351: 'असता,', 352: 'त्याने', 353: 'आणखी', 354: 'दोघांची', 355: 'नावे', 356: 'सांगितली.', 357: 'न्यायालयात', 358: 'गेले', 359: 'सदर', 360: 'तरुणाच्या', 361: 'मृत्यूप्रकरणी', 362: 'पोलिसांनी', 363: 'अज्ञात', 364: 'व्यक्तीविरोधात', 365: 'हत्येचा', 366: 'गुन्हा', 367: 'दाखल', 368: 'केला.', 369: 'यहोवा', 370: 'सियोनेस', 371: 'म्हणतो:', 372: '“राष्ट्रांची', 373: 'संपत्ति', 374: 'तुजकडे', 375: 'आणावी,', 376: 'त्यांचे', 377: 'राजे', 378: 'मिरवीत', 379: 'आणावे', 380: 'म्हणून', 381: 'तुझ्या', 382: 'वेशी', 383: 'सतत', 384: 'उघड्या', 385: 'राहतील,', 386: 'अहोरात्र', 387: 'बंद', 388: 'राहणार', 389: 'टॉमला', 390: 'हलवायला', 391: 'नका.', 392: 'वजन', 393: 'नियंत्रित', 394: '-', 395: 'दरम्यान,', 396: 'अमित', 397: 'शहा', 398: 'यांच्या', 399: 'सोबत', 400: 'भाजपचे', 401: 'कार्यकारी', 402: 'अध्यक्ष', 403: 'जे.', 404: 'पी.', 405: 'नड्डादेखील', 406: 'उपस्थित', 407: 'अशातच', 408: '‘ठग्स', 409: 'ऑफ', 410: 'हिंदोस्तान’', 411: 'चित्रपटाच्या', 412: 'ट्रेलर', 413: 'लॉन्च', 414: 'वेळी', 415: 'अमिताभ', 416: 'बच्चन', 417: 'तनुश्री', 418: 'दत्ता', 419: 'नाना', 420: 'पाटेकर', 421: 'प्रकरणावर', 422: 'मत', 423: 'विचारले', 424: 'यामध्ये', 425: 'शहरातील', 426: 'पर्जन्य', 427: 'जलवाहिन्यांची', 428: 'क्षमता', 429: '25', 430: 'मिलीमीटर', 431: 'असल्याने', 432: 'अतिवृष्टीत', 433: 'पावसाचे', 434: 'पाणी', 435: 'वाहून', 436: 'जाण्यास', 437: 'अडथळा', 438: 'निर्माण', 439: 'झाल्यामुळेच', 440: 'साचते.', 441: 'एक', 442: 'पॅन', 443: 'मध्ये,', 444: 'साखर', 445: 'कप', 446: 'ओतणे', 447: 'चमचे', 448: 'दोन', 449: 'ओतणे.', 450: 'यामुळे', 451: 'शेतकºयांचा', 452: 'काढणी', 453: 'खर्चही', 454: 'होईल.', 455: 'तपशील', 456: 'अचूक', 457: 'भरला', 458: 'पाहिजे.', 459: 'कोणाच्याच', 460: 'संपर्कात', 461: 'नव्हता.', 462: 'नागरिकत्व', 463: 'सुधारणा', 464: 'विधेयकात', 465: 'नेमकं', 466: 'काय?', 467: 'अखेर', 468: 'लोकसभा', 469: 'निवडणुकीत', 470: 'पक्षाने', 471: 'सपाटून', 472: 'मार', 473: 'खाल्ल्यानंतर', 474: 'राजीनामा', 475: 'दिला.', 476: 'तुम्ही', 477: 'सुद्धा', 478: 'आमचेच', 479: 'आहात.', 480: 'जीवात्मा', 481: 'विश्वात्मा', 482: 'यांच्यातील', 483: 'एकत्व', 484: 'अनुभवण्याची', 485: 'पद्धत', 486: 'असेही', 487: 'याचे', 488: 'वर्णन', 489: 'केले', 490: 'जाते.', 491: 'राहुल', 492: 'गांधी', 493: 'यांनीच', 494: 'अध्यक्षपदी', 495: 'रहावे.', 496: 'कार्तिक', 497: 'आर्यन,', 498: 'लक्ष', 499: 'लालवाणी', 500: 'जान्हवी', 501: 'कपूर', 502: 'काम', 503: 'नथुराम', 504: 'गोडसे', 505: 'पुस्तकाच्या', 506: 'आतापर्यंत', 507: 'हिंदी,', 508: 'मराठी,', 509: 'इंग्रजी', 510: 'गुजराती', 511: 'भाषांतील', 512: 'आवृत्या', 513: 'प्रसिद्ध', 514: 'झाल्या', 515: 'होत्या.', 516: 'त्यामुळे', 517: 'त्यांचं', 518: 'पुढे', 519: 'झालं', 520: 'कळू', 521: 'शकलं', 522: 'यांच्याबद्दल', 523: 'लिमिटेड', 524: 'पंतप्रधान', 525: 'कार्यालय', 526: 'ऐतिहासिक', 527: 'यशानंतर', 528: 'नरेंद्र', 529: 'मोदी', 530: 'जागतिक', 531: 'नेत्यांकडून', 532: 'शुभेच्छा', 533: 'नवी', 534: 'दिल्ली,', 535: 'मे', 536: '2019', 537: 'मिळवलेल्या', 538: 'नेत्यांनी', 539: 'पंतप्रधानांना', 540: 'दुसऱ्यांदा', 541: 'विजयी', 542: 'झाल्याबद्दल', 543: 'दिल्या', 544: '(', 545: 'नीतिसूत्रे', 546: '४:', 547: '१८)', 548: 'बायबलचा', 549: 'अभ्यास', 550: 'त्यातील', 551: 'सल्ला', 552: 'आपल्या', 553: 'जीवनात', 554: 'लागू', 555: 'भल्या', 556: 'पहाटे', 557: 'अर्थात', 558: 'अंधार', 559: 'असतानाच', 560: 'प्रवासाला', 561: 'निघण्यासारखे', 562: 'काल', 563: 'इंग्रजीचा', 564: 'महिलेच्या', 565: 'मृत्यूचं', 566: 'कारण', 567: 'गुलदस्त्यात', 568: 'ऍडव्हान्टेज', 569: 'आसाम-', 570: 'गुंतवणूकदार', 571: 'परिषद', 572: '2018', 573: 'च्या', 574: 'उद्\\u200cघाटनपर', 575: 'सत्रात', 576: 'पंतप्रधानांनी', 577: 'केलेले', 578: 'संबोधन', 579: 'दिल्ली', 580: 'फेब्रुवारी', 581: 'भुतानचे', 582: 'शेरिंग', 583: 'टोबगे,', 584: 'आसामचे', 585: 'राज्यपाल', 586: 'प्रोफेसर', 587: 'जगदीश', 588: 'मुखी,', 589: 'मुख्यमंत्री', 590: 'सर्वानंद', 591: 'सोनोवाल,', 592: 'जगभरातून,', 593: 'विशेषतः', 594: 'आसियान', 595: 'देशातून', 596: 'आलेले', 597: 'प्रतिनिधी,', 598: 'देशभरातून', 599: 'उद्योगपती', 600: 'इतर', 601: 'मान्यवर,', 602: 'आजि', 603: 'एई', 604: 'होन-मिलोनत', 605: 'उपोस्थित', 606: 'आपोना-लोक', 607: 'होकोलोके', 608: 'मोई', 609: 'आंतोरिक', 610: 'हुभेसा', 611: 'ज्ञापोन', 612: 'कोरिसों।', 613: 'लोगोते', 614: 'ओखोमोर', 615: 'होमुहो', 616: 'राईजो-लोई', 617: 'मोर', 618: 'गोभीर', 619: 'श्रोधा', 620: 'कोरिसो।', 621: 'परिषदेत', 622: 'आपणा', 623: 'सर्वांचे', 624: 'स्वागत', 625: 'करतो.', 626: 'थोडा', 627: 'लाजरा', 628: 'उंच', 629: 'झाडावर', 630: 'वास्तव्य', 631: 'करून', 632: 'राहणारा', 633: 'प्राणी', 634: 'जखमींपैकी', 635: 'एकजण', 636: 'अत्यव्यस्थ', 637: 'असून', 638: 'अन्य', 639: 'दोघेजण', 640: 'गंभीर', 641: 'जखमी', 642: 'झाले', 643: 'मध्ये', 644: 'वाटाघाटीनंतर', 645: 'केंद्र', 646: 'सरकारला', 647: '28,797', 648: 'कोटी', 649: 'रुपये', 650: 'राज्य', 651: 'सरकारांना', 652: '34,020', 653: 'एकूण', 654: 'महसूल', 655: 'मिळाला.', 656: 'अशी', 657: 'माहिती', 658: 'कोंढवा', 659: 'दिली.', 660: 'शिक्षणमंत्री', 661: 'रमेश', 662: 'पोखरियाल', 663: 'निशंक', 664: 'यांनी', 665: 'दिलेल्या', 666: 'माहितीच्या', 667: 'आधारे', 668: 'देण्यात', 669: 'आले', 670: 'सिद्धरामय्या', 671: 'म्हणाले?', 672: 'ह्या', 673: 'आदेशचा', 674: 'वापर', 675: 'करण्यापूर्वी', 676: 'डिबगरला', 677: 'उघडणे', 678: 'आवश्यक', 679: 'आहे', 680: 'पण', 681: 'जर', 682: 'खरेच', 683: 'एकमेकांना', 684: 'जाणून', 685: 'घेतले', 686: 'आपले', 687: 'बदलू', 688: 'शकतो'}\n"
          ]
        }
      ]
    }
  ]
}